{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m################### Importing Libraries ######################\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/ayyappaswamy/Desktop/mathsproject/parser/parser.ipynb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m train_df\u001B[38;5;241m.\u001B[39minfo()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/io/parsers/readers.py:586\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    571\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    572\u001B[0m     dialect,\n\u001B[1;32m    573\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    582\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    583\u001B[0m )\n\u001B[1;32m    584\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 586\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/io/parsers/readers.py:488\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1047\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread\u001B[39m(\u001B[38;5;28mself\u001B[39m, nrows\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1046\u001B[0m     nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m-> 1047\u001B[0m     index, columns, col_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1050\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m col_dict:\n\u001B[1;32m   1051\u001B[0m             \u001B[38;5;66;03m# Any column is actually fine:\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:224\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 224\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    226\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:801\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:857\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:843\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1925\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mParserError\u001B[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "################### Importing Libraries ######################\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('/Users/ayyappaswamy/Desktop/mathsproject/parser/parser.ipynb')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############ Count number of Categorical and Numerical Columns ######################\n",
    "train_df = train_df.drop(columns=['Loan_ID']) ## Dropping Loan ID\n",
    "categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Credit_History','Loan_Amount_Term']\n",
    "#categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Loan_Amount_Term']\n",
    "\n",
    "print(categorical_columns)\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n",
    "print(numerical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Data Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(4,2,figsize=(12,15))\n",
    "for idx,cat_col in enumerate(categorical_columns):\n",
    "    row,col = idx//2,idx%2\n",
    "    sns.countplot(x=cat_col,data=train_df,hue='Loan_Status',ax=axes[row,col])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(17,5))\n",
    "for idx,cat_col in enumerate(numerical_columns):\n",
    "    sns.boxplot(y=cat_col,data=train_df,x='Loan_Status',ax=axes[idx])\n",
    "\n",
    "print(train_df[numerical_columns].describe())\n",
    "plt.subplots_adjust(hspace=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Encoding categrical Features: ##########\n",
    "train_df_encoded = pd.get_dummies(train_df,drop_first=True)\n",
    "train_df_encoded.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########## Split Features and Target Varible ############\n",
    "X = train_df_encoded.drop(columns='Loan_Status_Y')\n",
    "y = train_df_encoded['Loan_Status_Y']\n",
    "\n",
    "################# Splitting into Train -Test Data #######\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify =y,random_state =42)\n",
    "############### Handling/Imputing Missing values #############\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp_train = imp.fit(X_train)\n",
    "X_train = imp_train.transform(X_train)\n",
    "X_test_imp = imp_train.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train,y_train)\n",
    "y_pred = tree_clf.predict(X_train)\n",
    "print(\"Training Data Set Accuracy: \", accuracy_score(y_train,y_pred))\n",
    "print(\"Training Data F1 Score \", f1_score(y_train,y_pred))\n",
    "\n",
    "print(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "val_accuracy = []\n",
    "training_f1 = []\n",
    "val_f1 = []\n",
    "tree_depths = []\n",
    "\n",
    "for depth in range(1,20):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    tree_clf.fit(X_train,y_train)\n",
    "    y_training_pred = tree_clf.predict(X_train)\n",
    "\n",
    "    training_acc = accuracy_score(y_train,y_training_pred)\n",
    "    train_f1 = f1_score(y_train,y_training_pred)\n",
    "    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()\n",
    "    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()\n",
    "\n",
    "    training_accuracy.append(training_acc)\n",
    "    val_accuracy.append(val_mean_accuracy)\n",
    "    training_f1.append(train_f1)\n",
    "    val_f1.append(val_mean_f1)\n",
    "    tree_depths.append(depth)\n",
    "\n",
    "\n",
    "Tuning_Max_depth = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Max_Depth\": tree_depths }\n",
    "Tuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)\n",
    "\n",
    "plot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Max_Depth\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "dot_data = tree.export_graphviz(tree_clf,feature_names = X.columns.tolist())\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "val_accuracy = []\n",
    "training_f1 = []\n",
    "val_f1 = []\n",
    "min_samples_leaf = []\n",
    "import numpy as np\n",
    "for samples_leaf in range(1,80,3): ### Sweeping from 1% samples to 10% samples per leaf\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf = samples_leaf)\n",
    "    tree_clf.fit(X_train,y_train)\n",
    "    y_training_pred = tree_clf.predict(X_train)\n",
    "\n",
    "    training_acc = accuracy_score(y_train,y_training_pred)\n",
    "    train_f1 = f1_score(y_train,y_training_pred)\n",
    "    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()\n",
    "    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()\n",
    "\n",
    "    training_accuracy.append(training_acc)\n",
    "    val_accuracy.append(val_mean_accuracy)\n",
    "    training_f1.append(train_f1)\n",
    "    val_f1.append(val_mean_f1)\n",
    "    min_samples_leaf.append(samples_leaf)\n",
    "\n",
    "\n",
    "Tuning_min_samples_leaf = {\"Training Accuracy\": training_accuracy, \"Validation Accuracy\": val_accuracy, \"Training F1\": training_f1, \"Validation F1\":val_f1, \"Min_Samples_leaf\": min_samples_leaf }\n",
    "Tuning_min_samples_leaf_df = pd.DataFrame.from_dict(Tuning_min_samples_leaf)\n",
    "\n",
    "plot_df = Tuning_min_samples_leaf_df.melt('Min_Samples_leaf',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Min_Samples_leaf\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf = 35)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "y_pred = tree_clf.predict(X_test_imp)\n",
    "print(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Test F1 Score: \",f1_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix on Test Data\")\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,max_depth=3,min_samples_leaf = 10)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_pred = rf_clf.predict(X_train)\n",
    "print(\"Train F1 Score \", f1_score(y_train,y_pred))\n",
    "print(\"Train Accuracy \", accuracy_score(y_train,y_pred))\n",
    "\n",
    "print(\"Validation Mean F1 Score: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Mean Accuracy: \",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test_imp)\n",
    "print(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Test F1 Score: \",f1_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix on Test Data\")\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "train_accuracies = []\n",
    "train_f1_scores = []\n",
    "test_accuracies = []\n",
    "test_f1_scores = []\n",
    "thresholds = []\n",
    "\n",
    "#for thresh in np.linspace(0.1,0.9,8): ## Sweeping from threshold of 0.1 to 0.9\n",
    "for thresh in np.arange(0.1,0.9,0.1): ## Sweeping from threshold of 0.1 to 0.9\n",
    "    logreg_clf = LogisticRegression(solver='liblinear')\n",
    "    logreg_clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred_train_thresh = logreg_clf.predict_proba(X_train)[:,1]\n",
    "    y_pred_train = (y_pred_train_thresh > thresh).astype(int)\n",
    "\n",
    "    train_acc = accuracy_score(y_train,y_pred_train)\n",
    "    train_f1 = f1_score(y_train,y_pred_train)\n",
    "\n",
    "    y_pred_test_thresh = logreg_clf.predict_proba(X_test_imp)[:,1]\n",
    "    y_pred_test = (y_pred_test_thresh > thresh).astype(int)\n",
    "\n",
    "    test_acc = accuracy_score(y_test,y_pred_test)\n",
    "    test_f1 = f1_score(y_test,y_pred_test)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_f1_scores.append(test_f1)\n",
    "    thresholds.append(thresh)\n",
    "\n",
    "\n",
    "Threshold_logreg = {\"Training Accuracy\": train_accuracies, \"Test Accuracy\": test_accuracies, \"Training F1\": train_f1_scores, \"Test F1\":test_f1_scores, \"Decision Threshold\": thresholds }\n",
    "Threshold_logreg_df = pd.DataFrame.from_dict(Threshold_logreg)\n",
    "\n",
    "plot_df = Threshold_logreg_df.melt('Decision Threshold',var_name='Metrics',value_name=\"Values\")\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "sns.pointplot(x=\"Decision Threshold\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresh = 0.4 ### Threshold chosen from above Curves\n",
    "y_pred_test_thresh = logreg_clf.predict_proba(X_test_imp)[:,1]\n",
    "y_pred = (y_pred_test_thresh > thresh).astype(int)\n",
    "print(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Test F1 Score: \",f1_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix on Test Data\")\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}